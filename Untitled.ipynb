{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "os.chdir(r'D:\\spoj\\tweet sentiment\\New folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train=pd.read_csv(\"Data/train.csv\")\n",
    "test=pd.read_csv(\"Data/test.csv\")\n",
    "#train=pd.read_csv(\"Data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27481, 4)\n",
      "(3534, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']=train['text'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    return text.lower()\n",
    "    return re.sub(r'\\d+', '', text) \n",
    "    return  \" \".join(text.split()) # remove white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "train['text'] = train['text'].apply(lambda x:''.join([i for i in x \n",
    "                                                  if i not in string.punctuation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']=train['text'].apply(lambda X:clean_text(str(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove default stopwords\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "  \n",
    "# remove stopwords function \n",
    "def remove_stopwords(text): \n",
    "    stop_words = set(stopwords.words(\"english\")) \n",
    "    word_tokens = word_tokenize(text) \n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words] \n",
    "    return filtered_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['stop_words']=train['text'].apply(lambda x:remove_stopwords(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>[boss, bullying]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sons, couldnt, put, releases, already, bought]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "      <td>[wish, could, come, see, u, denver, husband, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>ive wondered about rake to  the client has ma...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ive, wondered, rake, client, made, clear, net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>yay good for both of you enjoy the break  you...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[yay, good, enjoy, break, probably, need, hect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>but it was worth it</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[worth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>all this flirting going on  the atg smiles ...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[flirting, going, atg, smiles, yay, hugs]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                  id have responded if i were going   \n",
       "1      549e992a42         sooo sad i will miss you here in san diego   \n",
       "2      088c60f138                             my boss is bullying me   \n",
       "3      9642c003ef                      what interview leave me alone   \n",
       "4      358bd9e861   sons of  why couldnt they put them on the rel...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on denver  husband l...   \n",
       "27477  4f4c4fc327   ive wondered about rake to  the client has ma...   \n",
       "27478  f67aae2310   yay good for both of you enjoy the break  you...   \n",
       "27479  ed167662a5                              but it was worth it     \n",
       "27480  6f7127d9d7     all this flirting going on  the atg smiles ...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "0                    I`d have responded, if I were going   neutral   \n",
       "1                                               Sooo SAD  negative   \n",
       "2                                            bullying me  negative   \n",
       "3                                         leave me alone  negative   \n",
       "4                                          Sons of ****,  negative   \n",
       "...                                                  ...       ...   \n",
       "27476                                             d lost  negative   \n",
       "27477                                      , don`t force  negative   \n",
       "27478                          Yay good for both of you.  positive   \n",
       "27479                         But it was worth it  ****.  positive   \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral   \n",
       "\n",
       "                                              stop_words  \n",
       "0                                 [id, responded, going]  \n",
       "1                          [sooo, sad, miss, san, diego]  \n",
       "2                                       [boss, bullying]  \n",
       "3                              [interview, leave, alone]  \n",
       "4        [sons, couldnt, put, releases, already, bought]  \n",
       "...                                                  ...  \n",
       "27476  [wish, could, come, see, u, denver, husband, l...  \n",
       "27477  [ive, wondered, rake, client, made, clear, net...  \n",
       "27478  [yay, good, enjoy, break, probably, need, hect...  \n",
       "27479                                            [worth]  \n",
       "27480          [flirting, going, atg, smiles, yay, hugs]  \n",
       "\n",
       "[27480 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization:**** Like stemming, lemmatization also converts a word to its root form. The only difference is that lemmatization ensures that the root word belongs to the language. We will get valid words if we use lemmatization. In NLTK, we use the WordNetLemmatizer to get the lemmas of words. We also need to provide a context for the lemmatization. So, we add the part-of-speech as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "# lemmatize string \n",
    "def lemmatize_word(text): \n",
    "    word_tokens = word_tokenize(text) \n",
    "    # provide context i.e. part-of-speech \n",
    "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in word_tokens] \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['lemmatize']=train['stop_words'].apply(lambda x:lemmatize_word(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>lemmatize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "      <td>[[, 'id, ', ,, 'responded, ', ,, 'going, ', ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "      <td>[[, 'sooo, ', ,, 'sad, ', ,, 'miss, ', ,, 'san...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>[boss, bullying]</td>\n",
       "      <td>[[, 'boss, ', ,, 'bullying, ', ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "      <td>[[, 'interview, ', ,, 'leave, ', ,, 'alone, ', ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sons, couldnt, put, releases, already, bought]</td>\n",
       "      <td>[[, 'sons, ', ,, 'couldnt, ', ,, 'put, ', ,, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "      <td>[wish, could, come, see, u, denver, husband, l...</td>\n",
       "      <td>[[, 'wish, ', ,, 'could, ', ,, 'come, ', ,, 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>ive wondered about rake to  the client has ma...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ive, wondered, rake, client, made, clear, net...</td>\n",
       "      <td>[[, 'ive, ', ,, 'wondered, ', ,, 'rake, ', ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>yay good for both of you enjoy the break  you...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[yay, good, enjoy, break, probably, need, hect...</td>\n",
       "      <td>[[, 'yay, ', ,, 'good, ', ,, 'enjoy, ', ,, 'br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>but it was worth it</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[worth]</td>\n",
       "      <td>[[, 'worth, ', ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>all this flirting going on  the atg smiles ...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[flirting, going, atg, smiles, yay, hugs]</td>\n",
       "      <td>[[, 'flirting, ', ,, 'going, ', ,, 'atg, ', ,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                  id have responded if i were going   \n",
       "1      549e992a42         sooo sad i will miss you here in san diego   \n",
       "2      088c60f138                             my boss is bullying me   \n",
       "3      9642c003ef                      what interview leave me alone   \n",
       "4      358bd9e861   sons of  why couldnt they put them on the rel...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on denver  husband l...   \n",
       "27477  4f4c4fc327   ive wondered about rake to  the client has ma...   \n",
       "27478  f67aae2310   yay good for both of you enjoy the break  you...   \n",
       "27479  ed167662a5                              but it was worth it     \n",
       "27480  6f7127d9d7     all this flirting going on  the atg smiles ...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "0                    I`d have responded, if I were going   neutral   \n",
       "1                                               Sooo SAD  negative   \n",
       "2                                            bullying me  negative   \n",
       "3                                         leave me alone  negative   \n",
       "4                                          Sons of ****,  negative   \n",
       "...                                                  ...       ...   \n",
       "27476                                             d lost  negative   \n",
       "27477                                      , don`t force  negative   \n",
       "27478                          Yay good for both of you.  positive   \n",
       "27479                         But it was worth it  ****.  positive   \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral   \n",
       "\n",
       "                                              stop_words  \\\n",
       "0                                 [id, responded, going]   \n",
       "1                          [sooo, sad, miss, san, diego]   \n",
       "2                                       [boss, bullying]   \n",
       "3                              [interview, leave, alone]   \n",
       "4        [sons, couldnt, put, releases, already, bought]   \n",
       "...                                                  ...   \n",
       "27476  [wish, could, come, see, u, denver, husband, l...   \n",
       "27477  [ive, wondered, rake, client, made, clear, net...   \n",
       "27478  [yay, good, enjoy, break, probably, need, hect...   \n",
       "27479                                            [worth]   \n",
       "27480          [flirting, going, atg, smiles, yay, hugs]   \n",
       "\n",
       "                                               lemmatize  \n",
       "0         [[, 'id, ', ,, 'responded, ', ,, 'going, ', ]]  \n",
       "1      [[, 'sooo, ', ,, 'sad, ', ,, 'miss, ', ,, 'san...  \n",
       "2                      [[, 'boss, ', ,, 'bullying, ', ]]  \n",
       "3      [[, 'interview, ', ,, 'leave, ', ,, 'alone, ', ]]  \n",
       "4      [[, 'sons, ', ,, 'couldnt, ', ,, 'put, ', ,, '...  \n",
       "...                                                  ...  \n",
       "27476  [[, 'wish, ', ,, 'could, ', ,, 'come, ', ,, 's...  \n",
       "27477  [[, 'ive, ', ,, 'wondered, ', ,, 'rake, ', ,, ...  \n",
       "27478  [[, 'yay, ', ,, 'good, ', ,, 'enjoy, ', ,, 'br...  \n",
       "27479                                  [[, 'worth, ', ]]  \n",
       "27480  [[, 'flirting, ', ,, 'going, ', ,, 'atg, ', ,,...  \n",
       "\n",
       "[27480 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=train['text']\n",
    "Y=train['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(X):\n",
    "    newlist = []\n",
    "    for alist in X:\n",
    "        newlist.append(alist[0].split(' '))\n",
    "    return newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "vectorizer = CountVectorizer(tokenizer=my_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, encoding='utf-8', decode_error='ignore',lowercase=True)\n",
    "vectorizer.fit(X_train)\n",
    "X_train=vectorizer.transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training data is: 0.7880071696268535\n",
      "Score on testing data is: 0.6828757305105304\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regresion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "print(\"Score on training data is: \"+str(model.score(X_train,Y_train)))\n",
    "print(\"Score on testing data is: \"+str(model.score(X_test,Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Here 0 denotes a negative sentiment\n",
    "model.predict(X_test[78])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(stop_words,'stopwords.pkl') \n",
    "joblib.dump(model,'model.pkl')\n",
    "joblib.dump(vectorizer,'vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.externals import joblib\n",
    "model = joblib.load(\"model.pkl\")\n",
    "model.predict([\"Now, we can use this object, and we no longer need to train our classifier every time we wanted to use it to classify.\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-66-c204fb4eb3dc>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-66-c204fb4eb3dc>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    new_dict.predict(])\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "infile = open('vectorizer.pkl','rb')\n",
    "new_dict = pickle.load(infile)\n",
    "new_dict.predict(])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vectorizer.transform([\"i have got a new phone. its from Apple.. and i love it!\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'negative' 'negative' ... 'positive' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "def classify(document):\n",
    "     X = vectorizer.transform([document])\n",
    "     Y =model.predict(vectorizer.transform(X))\n",
    "     return Y\n",
    "print(classify(str(\" we have developed many machine learning models \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral'], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "documents=[\" we have developed many machine learning models\"]\n",
    "x2=vectorizer.transform(documents)\n",
    "model.predict((x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
