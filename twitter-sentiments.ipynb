{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\n",
    "ss = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27481, 4)\n",
      "(3534, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorative Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']=train['text'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    return text.lower()\n",
    "    return re.sub(r'\\d+', '', text) \n",
    "    return  \" \".join(text.split()) # remove white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "train['text'] = train['text'].apply(lambda x:''.join([i for i in x \n",
    "                                                  if i not in string.punctuation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']=train['text'].apply(lambda X:clean_text(str(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>ive wondered about rake to  the client has ma...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>yay good for both of you enjoy the break  you...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>but it was worth it</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>all this flirting going on  the atg smiles ...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                  id have responded if i were going   \n",
       "1      549e992a42         sooo sad i will miss you here in san diego   \n",
       "2      088c60f138                             my boss is bullying me   \n",
       "3      9642c003ef                      what interview leave me alone   \n",
       "4      358bd9e861   sons of  why couldnt they put them on the rel...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on denver  husband l...   \n",
       "27477  4f4c4fc327   ive wondered about rake to  the client has ma...   \n",
       "27478  f67aae2310   yay good for both of you enjoy the break  you...   \n",
       "27479  ed167662a5                              but it was worth it     \n",
       "27480  6f7127d9d7     all this flirting going on  the atg smiles ...   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "0                    I`d have responded, if I were going   neutral  \n",
       "1                                               Sooo SAD  negative  \n",
       "2                                            bullying me  negative  \n",
       "3                                         leave me alone  negative  \n",
       "4                                          Sons of ****,  negative  \n",
       "...                                                  ...       ...  \n",
       "27476                                             d lost  negative  \n",
       "27477                                      , don`t force  negative  \n",
       "27478                          Yay good for both of you.  positive  \n",
       "27479                         But it was worth it  ****.  positive  \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral  \n",
       "\n",
       "[27480 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove default stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "  \n",
    "# remove stopwords function \n",
    "def remove_stopwords(text): \n",
    "    stop_words = set(stopwords.words(\"english\")) \n",
    "    word_tokens = word_tokenize(text) \n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words] \n",
    "    return filtered_text \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['stop_words']=train['text'].apply(lambda x:remove_stopwords(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming**:\n",
    "Stemming is the process of getting the root form of a word. Stem or root is the part to which inflectional affixes (-ed, -ize, -de, -s, etc.) are added. The stem of a word is created by removing the prefix or suffix of a word. So, stemming a word may not result in actual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "stemmer = PorterStemmer() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(text): \n",
    "    word_tokens = word_tokenize(text) \n",
    "    stems = [stemmer.stem(word) for word in word_tokens] \n",
    "    return stems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['stemming']=train['stop_words'].apply(lambda x:stem_words(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "      <td>[[, 'id, ', ,, 'respond, ', ,, 'go, ', ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "      <td>[[, 'sooo, ', ,, 'sad, ', ,, 'miss, ', ,, 'san...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>[boss, bullying]</td>\n",
       "      <td>[[, 'boss, ', ,, 'bulli, ', ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "      <td>[[, 'interview, ', ,, 'leav, ', ,, 'alon, ', ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sons, couldnt, put, releases, already, bought]</td>\n",
       "      <td>[[, 'son, ', ,, 'couldnt, ', ,, 'put, ', ,, 'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "      <td>[wish, could, come, see, u, denver, husband, l...</td>\n",
       "      <td>[[, 'wish, ', ,, 'could, ', ,, 'come, ', ,, 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>ive wondered about rake to  the client has ma...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ive, wondered, rake, client, made, clear, net...</td>\n",
       "      <td>[[, 'ive, ', ,, 'wonder, ', ,, 'rake, ', ,, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>yay good for both of you enjoy the break  you...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[yay, good, enjoy, break, probably, need, hect...</td>\n",
       "      <td>[[, 'yay, ', ,, 'good, ', ,, 'enjoy, ', ,, 'br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>but it was worth it</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[worth]</td>\n",
       "      <td>[[, 'worth, ', ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>all this flirting going on  the atg smiles ...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[flirting, going, atg, smiles, yay, hugs]</td>\n",
       "      <td>[[, 'flirt, ', ,, 'go, ', ,, 'atg, ', ,, 'smil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                  id have responded if i were going   \n",
       "1      549e992a42         sooo sad i will miss you here in san diego   \n",
       "2      088c60f138                             my boss is bullying me   \n",
       "3      9642c003ef                      what interview leave me alone   \n",
       "4      358bd9e861   sons of  why couldnt they put them on the rel...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on denver  husband l...   \n",
       "27477  4f4c4fc327   ive wondered about rake to  the client has ma...   \n",
       "27478  f67aae2310   yay good for both of you enjoy the break  you...   \n",
       "27479  ed167662a5                              but it was worth it     \n",
       "27480  6f7127d9d7     all this flirting going on  the atg smiles ...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "0                    I`d have responded, if I were going   neutral   \n",
       "1                                               Sooo SAD  negative   \n",
       "2                                            bullying me  negative   \n",
       "3                                         leave me alone  negative   \n",
       "4                                          Sons of ****,  negative   \n",
       "...                                                  ...       ...   \n",
       "27476                                             d lost  negative   \n",
       "27477                                      , don`t force  negative   \n",
       "27478                          Yay good for both of you.  positive   \n",
       "27479                         But it was worth it  ****.  positive   \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral   \n",
       "\n",
       "                                              stop_words  \\\n",
       "0                                 [id, responded, going]   \n",
       "1                          [sooo, sad, miss, san, diego]   \n",
       "2                                       [boss, bullying]   \n",
       "3                              [interview, leave, alone]   \n",
       "4        [sons, couldnt, put, releases, already, bought]   \n",
       "...                                                  ...   \n",
       "27476  [wish, could, come, see, u, denver, husband, l...   \n",
       "27477  [ive, wondered, rake, client, made, clear, net...   \n",
       "27478  [yay, good, enjoy, break, probably, need, hect...   \n",
       "27479                                            [worth]   \n",
       "27480          [flirting, going, atg, smiles, yay, hugs]   \n",
       "\n",
       "                                                stemming  \n",
       "0              [[, 'id, ', ,, 'respond, ', ,, 'go, ', ]]  \n",
       "1      [[, 'sooo, ', ,, 'sad, ', ,, 'miss, ', ,, 'san...  \n",
       "2                         [[, 'boss, ', ,, 'bulli, ', ]]  \n",
       "3        [[, 'interview, ', ,, 'leav, ', ,, 'alon, ', ]]  \n",
       "4      [[, 'son, ', ,, 'couldnt, ', ,, 'put, ', ,, 'r...  \n",
       "...                                                  ...  \n",
       "27476  [[, 'wish, ', ,, 'could, ', ,, 'come, ', ,, 's...  \n",
       "27477  [[, 'ive, ', ,, 'wonder, ', ,, 'rake, ', ,, 'c...  \n",
       "27478  [[, 'yay, ', ,, 'good, ', ,, 'enjoy, ', ,, 'br...  \n",
       "27479                                  [[, 'worth, ', ]]  \n",
       "27480  [[, 'flirt, ', ,, 'go, ', ,, 'atg, ', ,, 'smil...  \n",
       "\n",
       "[27480 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatization:**************\n",
    "Like stemming, lemmatization also converts a word to its root form. The only difference is that lemmatization ensures that the root word belongs to the language. We will get valid words if we use lemmatization. In NLTK, we use the WordNetLemmatizer to get the lemmas of words. We also need to provide a context for the lemmatization. So, we add the part-of-speech as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "# lemmatize string \n",
    "def lemmatize_word(text): \n",
    "    word_tokens = word_tokenize(text) \n",
    "    # provide context i.e. part-of-speech \n",
    "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in word_tokens] \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['lemmatize']=train['stop_words'].apply(lambda x:lemmatize_word(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>stemming</th>\n",
       "      <th>lemmatize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[id, responded, going]</td>\n",
       "      <td>[[, 'id, ', ,, 'respond, ', ,, 'go, ', ]]</td>\n",
       "      <td>[[, 'id, ', ,, 'responded, ', ,, 'going, ', ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sooo, sad, miss, san, diego]</td>\n",
       "      <td>[[, 'sooo, ', ,, 'sad, ', ,, 'miss, ', ,, 'san...</td>\n",
       "      <td>[[, 'sooo, ', ,, 'sad, ', ,, 'miss, ', ,, 'san...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>[boss, bullying]</td>\n",
       "      <td>[[, 'boss, ', ,, 'bulli, ', ]]</td>\n",
       "      <td>[[, 'boss, ', ,, 'bullying, ', ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>[interview, leave, alone]</td>\n",
       "      <td>[[, 'interview, ', ,, 'leav, ', ,, 'alon, ', ]]</td>\n",
       "      <td>[[, 'interview, ', ,, 'leave, ', ,, 'alone, ', ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sons, couldnt, put, releases, already, bought]</td>\n",
       "      <td>[[, 'son, ', ,, 'couldnt, ', ,, 'put, ', ,, 'r...</td>\n",
       "      <td>[[, 'sons, ', ,, 'couldnt, ', ,, 'put, ', ,, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "      <td>[wish, could, come, see, u, denver, husband, l...</td>\n",
       "      <td>[[, 'wish, ', ,, 'could, ', ,, 'come, ', ,, 's...</td>\n",
       "      <td>[[, 'wish, ', ,, 'could, ', ,, 'come, ', ,, 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>ive wondered about rake to  the client has ma...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ive, wondered, rake, client, made, clear, net...</td>\n",
       "      <td>[[, 'ive, ', ,, 'wonder, ', ,, 'rake, ', ,, 'c...</td>\n",
       "      <td>[[, 'ive, ', ,, 'wondered, ', ,, 'rake, ', ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>yay good for both of you enjoy the break  you...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[yay, good, enjoy, break, probably, need, hect...</td>\n",
       "      <td>[[, 'yay, ', ,, 'good, ', ,, 'enjoy, ', ,, 'br...</td>\n",
       "      <td>[[, 'yay, ', ,, 'good, ', ,, 'enjoy, ', ,, 'br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>but it was worth it</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[worth]</td>\n",
       "      <td>[[, 'worth, ', ]]</td>\n",
       "      <td>[[, 'worth, ', ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>all this flirting going on  the atg smiles ...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[flirting, going, atg, smiles, yay, hugs]</td>\n",
       "      <td>[[, 'flirt, ', ,, 'go, ', ,, 'atg, ', ,, 'smil...</td>\n",
       "      <td>[[, 'flirting, ', ,, 'going, ', ,, 'atg, ', ,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                  id have responded if i were going   \n",
       "1      549e992a42         sooo sad i will miss you here in san diego   \n",
       "2      088c60f138                             my boss is bullying me   \n",
       "3      9642c003ef                      what interview leave me alone   \n",
       "4      358bd9e861   sons of  why couldnt they put them on the rel...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on denver  husband l...   \n",
       "27477  4f4c4fc327   ive wondered about rake to  the client has ma...   \n",
       "27478  f67aae2310   yay good for both of you enjoy the break  you...   \n",
       "27479  ed167662a5                              but it was worth it     \n",
       "27480  6f7127d9d7     all this flirting going on  the atg smiles ...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "0                    I`d have responded, if I were going   neutral   \n",
       "1                                               Sooo SAD  negative   \n",
       "2                                            bullying me  negative   \n",
       "3                                         leave me alone  negative   \n",
       "4                                          Sons of ****,  negative   \n",
       "...                                                  ...       ...   \n",
       "27476                                             d lost  negative   \n",
       "27477                                      , don`t force  negative   \n",
       "27478                          Yay good for both of you.  positive   \n",
       "27479                         But it was worth it  ****.  positive   \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral   \n",
       "\n",
       "                                              stop_words  \\\n",
       "0                                 [id, responded, going]   \n",
       "1                          [sooo, sad, miss, san, diego]   \n",
       "2                                       [boss, bullying]   \n",
       "3                              [interview, leave, alone]   \n",
       "4        [sons, couldnt, put, releases, already, bought]   \n",
       "...                                                  ...   \n",
       "27476  [wish, could, come, see, u, denver, husband, l...   \n",
       "27477  [ive, wondered, rake, client, made, clear, net...   \n",
       "27478  [yay, good, enjoy, break, probably, need, hect...   \n",
       "27479                                            [worth]   \n",
       "27480          [flirting, going, atg, smiles, yay, hugs]   \n",
       "\n",
       "                                                stemming  \\\n",
       "0              [[, 'id, ', ,, 'respond, ', ,, 'go, ', ]]   \n",
       "1      [[, 'sooo, ', ,, 'sad, ', ,, 'miss, ', ,, 'san...   \n",
       "2                         [[, 'boss, ', ,, 'bulli, ', ]]   \n",
       "3        [[, 'interview, ', ,, 'leav, ', ,, 'alon, ', ]]   \n",
       "4      [[, 'son, ', ,, 'couldnt, ', ,, 'put, ', ,, 'r...   \n",
       "...                                                  ...   \n",
       "27476  [[, 'wish, ', ,, 'could, ', ,, 'come, ', ,, 's...   \n",
       "27477  [[, 'ive, ', ,, 'wonder, ', ,, 'rake, ', ,, 'c...   \n",
       "27478  [[, 'yay, ', ,, 'good, ', ,, 'enjoy, ', ,, 'br...   \n",
       "27479                                  [[, 'worth, ', ]]   \n",
       "27480  [[, 'flirt, ', ,, 'go, ', ,, 'atg, ', ,, 'smil...   \n",
       "\n",
       "                                               lemmatize  \n",
       "0         [[, 'id, ', ,, 'responded, ', ,, 'going, ', ]]  \n",
       "1      [[, 'sooo, ', ,, 'sad, ', ,, 'miss, ', ,, 'san...  \n",
       "2                      [[, 'boss, ', ,, 'bullying, ', ]]  \n",
       "3      [[, 'interview, ', ,, 'leave, ', ,, 'alone, ', ]]  \n",
       "4      [[, 'sons, ', ,, 'couldnt, ', ,, 'put, ', ,, '...  \n",
       "...                                                  ...  \n",
       "27476  [[, 'wish, ', ,, 'could, ', ,, 'come, ', ,, 's...  \n",
       "27477  [[, 'ive, ', ,, 'wondered, ', ,, 'rake, ', ,, ...  \n",
       "27478  [[, 'yay, ', ,, 'good, ', ,, 'enjoy, ', ,, 'br...  \n",
       "27479                                  [[, 'worth, ', ]]  \n",
       "27480  [[, 'flirting, ', ,, 'going, ', ,, 'atg, ', ,,...  \n",
       "\n",
       "[27480 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=train['text']\n",
    "Y=train['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, encoding='utf-8', decode_error='ignore')\n",
    "vectorizer.fit(X_train)\n",
    "X_train=vectorizer.transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training data is: 0.7880071696268535\n",
      "Score on testing data is: 0.6828757305105304\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regresion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train,Y_train)\n",
    "print(\"Score on training data is: \"+str(model.score(X_train,Y_train)))\n",
    "print(\"Score on testing data is: \"+str(model.score(X_test,Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Here 0 denotes a negative sentiment\n",
    "model.predict(X_test[78])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'en_stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-418aec899b66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_stopwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'stopwords.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'model.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'vectorizer.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'en_stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(stop_words,'stopwords.pkl') \n",
    "joblib.dump(model,'model.pkl')\n",
    "joblib.dump(vectorizer,'vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes Classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,Y_train)\n",
    "clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message=\"id have responded if i were going\tI`d have responded, if I \"\n",
    "data=[message]\n",
    "data\n",
    "vect = vectorizer.transform(data).toarray()\n",
    "clf.predict(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.h5'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "text_classifier = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "text_classifier.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'random_tweets.h5'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_classifier.score(X_train, Y_train),text_classifier.score(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message=\"i hate myself\"\n",
    "data22=[message]\n",
    "vect=vectorizer.transform(data22).toarray()\n",
    "model.predict(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    text_classifier.predict(vectorizer.transform(vector.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score of the XGBoost Classifier\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train,Y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_test[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tender=\"['doctor', 'mbbs', 'student', 'found', 'shot', 'dead', 'hostel']\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "          ('LogReg', LogisticRegression()), \n",
    "          ('RF', RandomForestClassifier()),\n",
    "          ('MNB',MultinomialNB()),\n",
    "          ('XGB', XGBClassifier())\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores.append([\"Naive Bayes Classifier\"],[clf.score(X_train,Y_train)],[clf.score(X_test,Y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
